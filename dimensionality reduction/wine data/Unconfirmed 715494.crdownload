#!/usr/bin/env python
# coding: utf-8

# # Problem Statement:
# You work in XYZ Company as a Python. The company officials want you to write code for reducing the dimensions of a dataset
# Tasks to be performed:
# - Using load_digits function from sklearn import wines data
# - Take a look at the shape of image data
# - Import PCA, LDA and FactorAnalysis from Sklearn
# - Project data in 2 D space using the PCA, LDA and FactorAnalysis algorithm form sklearn
# - Take a look at the new data

# In[1]:


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.preprocessing import StandardScaler
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.decomposition import FactorAnalysis as FA
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split


# In[2]:


# importing the dataset
digits = datasets.load_wine()


# In[3]:


digits


# In[4]:


digits.target


# In[5]:


digits.target_names


# In[6]:


for image, label in zip(digits.data[0:5], digits.target[0:5]):
    print(image)
    print(label)


# In[7]:


for i,j in enumerate(['ele1','ele2','ele3']):
    print(i)
    print(j)


# In[8]:


#Displaying some of the images and labels
#import numpy as np
#import matplotlib.pyplot as plt

plt.figure(figsize=(20,4))
for index, (image, label) in enumerate(zip(digits.data[0:5], digits.target[0:5])):
    plt.subplot(1,5, index+1)
    plt.imshow(np.reshape(image, (8,8)), cmap=plt.cm.gray)
    plt.title(f"Training: {label}", fontsize=20 )  


# In[13]:


#digits.data[0:5]


# In[14]:


X = digits.data
y = digits.target

X.shape


# In[15]:


y.shape


# In[16]:


#splitting the data 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=34)


# In[17]:


y_train


# In[18]:


#feature Scaling
sc = StandardScaler()
X_train = sc.fit_transform(X_train)

X_test = sc.transform(X_test)


# In[19]:


from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)


# In[20]:


y_pred = rf.predict(X_test)
y_pred


# In[21]:


y_test


# In[22]:


from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

acc = accuracy_score(y_test, y_pred)


# In[23]:


acc


# In[24]:


print(confusion_matrix(y_test,y_pred))


# # LDA

# In[25]:


#LDA
lda = LinearDiscriminantAnalysis(n_components=9)
X_train = lda.fit_transform(X_train, y_train)
X_test = lda.transform(X_test) 
X_train.shape


# In[26]:


plt.imshow(np.reshape(X_train[1], (3,3)), cmap=plt.cm.gray)


# In[27]:


X_train


# In[28]:


#model Building 
from sklearn.ensemble import RandomForestClassifier

rf1 = RandomForestClassifier(n_estimators=100, random_state=42)
rf1.fit(X_train, y_train)


# In[29]:


#prediction
y_pred1 = rf1.predict(X_test)


# In[30]:


y_pred1


# In[31]:


y_test


# In[32]:


#accuracy Score
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

acc = accuracy_score(y_test, y_pred1)
cf = confusion_matrix(y_test, y_pred1)
clrep = classification_report(y_test, y_pred1)


# In[33]:


print(acc)


# In[34]:


cf


# In[35]:


'''
         0    1   2   3   4   5   6   7   8   9
   0    [32,  0,  0,  0,  1,  0,  0,  0,  0,  0],
    1   [ 0, 27,  1,  0,  0,  0,  0,  0,  0,  0],
    2   [ 0,  0, 31,  2,  0,  0,  0,  0,  0,  0],
    3   [ 0,  0,  0, 33,  0,  1,  0,  0,  0,  0],
    4   [ 0,  0,  0,  0, 45,  0,  0,  1,  0,  0],
    5   [ 0,  0,  0,  0,  0, 46,  0,  0,  1,  0],
    6   [ 0,  0,  0,  0,  1,  0, 34,  0,  0,  0],
    7   [ 0,  0,  0,  0,  0,  0,  0, 33,  0,  1],
    8   [ 0,  2,  0,  0,  0,  0,  0,  0, 27,  1],
    9   [ 0,  0,  0,  1,  1,  0,  0,  0,  1, 37]
'''


# In[36]:


print(clrep)


# In[37]:


import seaborn as sns
sns.heatmap(cf)


# In[38]:


y_test


# In[39]:


y_pred1


# In[40]:


def get_misclassified_index(y_pred,y_test):
    misclassification=[]#help us out to get the misclassified index value
    for index,(predicted,actual) in enumerate(zip(y_pred,y_test)):
        if predicted!=actual:
            misclassification.append(index)
            
    return misclassification


# In[41]:


misclassification = get_misclassified_index(y_pred1,y_test)


# In[42]:


misclassification


# In[ ]:





# In[43]:


def plot_misclassifications(misclassification):
    plt.figure(figsize=(20,4))
    for index,wrong in enumerate(misclassification[0:5]):
        plt.subplot(1,5,index+1)
        plt.imshow(np.reshape(X_test[wrong],(3,3)),cmap=plt.cm.gray)
        plt.title("Predicted:{} Actual:{}".format(y_pred1[wrong],y_test[wrong]))


# In[44]:


plot_misclassifications(misclassification)


# # PCA

# In[48]:


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=34)


# In[49]:


sc = StandardScaler()
X_train = sc.fit_transform(X_train)

X_test = sc.transform(X_test)


# In[55]:


pca = PCA()
X_train = pca.fit_transform(X_train)
X_test = pca.transform(X_test)


# In[58]:


explained_variance = pca.explained_variance_ratio_
explained_variance


# In[61]:


def perfrom_pca(n):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
    pca = PCA(n_components=n)
    pca_x_train = pca.fit_transform(X_train)
    pca_x_test = pca.transform(X_test)
    classifier = RandomForestClassifier(max_depth=2, random_state=0)
    classifier.fit(pca_x_train, y_train)
    y_pred = classifier.predict(pca_x_test)
    cm = confusion_matrix(y_test, y_pred)
    print(x)
    print('Accuracy {0}\n\n'.format(accuracy_score(y_test, y_pred)))


# In[62]:


for x in range(1,64): perfrom_pca(x)


# In[64]:


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
pca = PCA(n_components=13)
pca_x_train = pca.fit_transform(X_train)
pca_x_test = pca.transform(X_test)
classifier = RandomForestClassifier(max_depth=2, random_state=0)
classifier.fit(pca_x_train, y_train)
y_pred = classifier.predict(pca_x_test)
cm = confusion_matrix(y_test, y_pred)
print(cm)
print('Accuracy {0}\n\n'.format(accuracy_score(y_test, y_pred)))


# In[65]:


pca_x_train


# In[66]:


y_test


# In[68]:


y_pred


# In[69]:


clrep = classification_report(y_test, y_pred)


# In[70]:


print(clrep)


# # FA

# In[81]:


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=34)


# In[82]:


sc = StandardScaler()
X_train = sc.fit_transform(X_train)

X_test = sc.transform(X_test)


# In[83]:


fa = FA()
fa_x_train = fa.fit_transform(X_train)
fa_x_test = fa.transform(X_test)
classifier = RandomForestClassifier(max_depth=2, random_state=0)
classifier.fit(fa_x_train, y_train)
y_pred = classifier.predict(fa_x_test)
cm = confusion_matrix(y_test, y_pred)
print(cm)
print('Accuracy {0}\n\n'.format(accuracy_score(y_test, y_pred)))


# In[84]:


fa_x_train


# In[85]:


y_test


# In[86]:


y_pred


# In[87]:


clrep = classification_report(y_test, y_pred)
print(clrep)


# In[ ]:




